{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BbZ1eCdmDSmq"},"source":["# EM Algorithm v1.2\n","This is the Revise version of EMCore written by Prof. Chang.\n","This algorithm is divided into the following steps:\n","\n","## Preprocessing\n","    1. Reading CSV File (csv)\n","    2. Creating OneHot Lot Encoding of Machines [1]_\n","    3. Preprocessing: Calculating LOT Information\n","    4. Preprocessing: Calculating Machine Information\n","\n","the initial yieldrate is calculated using Least Square and L-BFGS-B [2]_, and is\n","included id step 4 above.\n","\n","## EM Algorithm\n","    5. Running EM Algorithm\n","\n","## Report\n","    6. Saving reports to CSV\n","\n","## Optimization\n","some of the code is optimize based on Python Speed Performance Tips recommended\n","by python.org [3]. In this code, it could be seen commented as\n","``Optimizing:...``. One of them are avoiding dots (e.g. avoid multiple calls\n","of ``df.my_column``)\n","\n","\n","## References\n",".. [1] Jezrael. 2019. Answer on \"Create dummy variable of multiple columns with\n","   python\". One hot encoding with pandas \"get_dummies\" and different column and\n","   same values is seen as one values. `link <https://stackoverflow.com/\n","   questions/55182909/create-dummy-variable-of-multiple-columns-with-python>`_\n","\n",".. [2] The SciPy community. 2019. Limited-memory BFGS B. see: `scipy.optimize.\n","   fmin_l_bfgs_b <https://docs.scipy.org/doc/scipy/reference/generated/\n","   scipy.optimize.fmin_l_bfgs_b.html>`_\n","\n",".. [3] Python.org. 2016. Python Speed Performance Tips. `link <https://wiki.\n","   python.org/moin/PythonSpeed/PerformanceTips>`_"]},{"cell_type":"code","source":["!pip install pandas==1.5.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEwx2o848sTv","executionInfo":{"status":"ok","timestamp":1715068016853,"user_tz":-480,"elapsed":7859,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"82270dc7-a5c3-4329-b95d-35edc071fd48"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"EIciKdLvD-Yh"},"source":["\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"X9RpCTHaHGvx"},"source":["# Initializing Google Colab"]},{"cell_type":"code","metadata":{"id":"m1gO_osJD3Xx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715068019598,"user_tz":-480,"elapsed":2754,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"7ffa8163-5aa5-48d3-bfa6-0730e7a753e2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"29i0KCzQjEGN"},"source":["Please modify the path below to match your folder path\n","change \"ColabNotebook/TH\" with your folder path in your google drive"]},{"cell_type":"code","metadata":{"id":"g8U_SL-RV9UT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715068019599,"user_tz":-480,"elapsed":8,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"2a9856ee-b66e-4789-94d1-0add39110ae3"},"source":["cd '/content/gdrive/MyDrive/Colab Notebooks'"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"markdown","metadata":{"id":"eoxnJ_HrHP3B"},"source":["## checking required file"]},{"cell_type":"code","metadata":{"id":"dFgcpuHsN20C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715068020229,"user_tz":-480,"elapsed":636,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"6a00c420-92f2-4437-d0d4-c5fe1213b697"},"source":["!ls custom_utility.py\n","!ls test_case_1a.csv\n","!ls real_world_data.csv"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["custom_utility.py\n","test_case_1a.csv\n","real_world_data.csv\n"]}]},{"cell_type":"code","metadata":{"id":"AWjbZ-hoHb3q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715068020230,"user_tz":-480,"elapsed":19,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"8e68c2a1-8627-44a0-d1a0-0798e2c95a0d"},"source":["!cat custom_utility.py"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["# -*- coding: utf-8 -*-\r\n","\"\"\"\r\n","Created on Sat Jul 13 11:50:43 2019\r\n","\r\n","@author: Faster\r\n","\r\n","Importing:\r\n","    first, this file should be in the same folder as the importer, then\r\n","\r\n","    >>> import custom_utility as cu\r\n","\r\n","    or using Python's Relative imports, Every leading dot is another higher\r\n","    level in the hierarchy beginning with the current directory.\r\n","\r\n","    >>> import ...app.folder.file as cu\r\n","\r\n","Features:\r\n","    show_progress:\r\n","        Print the current progress in percentage\r\n","    check_time:\r\n","        Calculate and print time passes from ``time_start`` to ``time_end``.\r\n","\"\"\"\r\n","\r\n","import sys\r\n","\r\n","def show_progress(current_num, max_num, step_print=5, messages='',\r\n","                  force_show=False):\r\n","    \"\"\"\r\n","    Print the current progress in percentage\r\n","\r\n","    Parameter:\r\n","    ----------\r\n","    current_num, max_num: int\r\n","        The current number and the maximum number of the progress or loop\r\n","        (if used)\r\n","    step_print: int (optional)\r\n","        (unit is in percent) How often the message should be printed, the\r\n","        default is every 5 percent of ``max_num``.\r\n","    message: string (optional)\r\n","        Insert message in the beginning of printing percentage\r\n","    force_show: bool (optional)\r\n","        Printing for each progress no matter how small the progress is. If set\r\n","        to ``True``, It will disabled or ignore the step_print option.\r\n","\r\n","    This function does not return anything, It prints as function is called.\r\n","\r\n","    >>> show_progress(3, 100, messages='Current progress', force_show=True)\r\n","    Current progress 3%\r\n","    \"\"\"\r\n","\r\n","    #calculating real progress\r\n","    progress = (current_num/max_num*100)\r\n","\r\n","    # change to int, avoid too many printing, except is forced to\r\n","    progress = int(progress) if (force_show or (progress % 1) >= 0.93\r\n","                                 or (progress % 1) <= 0.07) else progress\r\n","\r\n","    #print progress\r\n","    if (progress % step_print) == 0 or force_show:\r\n","        msg = \"\\r%s %d%% \" %(messages, progress)\r\n","        sys.stdout.write(msg)\r\n","        sys.stdout.flush()\r\n","\r\n","def check_time(time_start, time_end):\r\n","    \"\"\"\r\n","    calculate time passed from ``time_start`` to ``time_end``.\r\n","\r\n","    Parameter:\r\n","    ----------\r\n","    time_start, time_end: time float format\r\n","        the argument should be in ``float`` numbers. It can use import time\r\n","        and use time.time() as input\r\n","\r\n","    this function does not return anything, It prints as function is called.\r\n","\r\n","    >>> check_time(11890.88, 21192.99) #sample time\r\n","    Time elapsed: 2 H : 35 M : 2.11 Sec\r\n","    \"\"\"\r\n","\r\n","    t_sec = round(time_end - time_start, 3)\r\n","    (t_min, t_sec) = divmod(t_sec, 60)\r\n","    (t_hour, t_min) = divmod(t_min, 60)\r\n","    print('Time elapsed: {} H : {} M : {} Sec'. \\\r\n","          format(round(t_hour), round(t_min), round(t_sec, 3)))\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"p1E-NdHRILiJ"},"source":["## Importing modules"]},{"cell_type":"code","source":["# import sys\n","# sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/custom_utility.py')"],"metadata":{"id":"iMVD_RNm1-D_","executionInfo":{"status":"ok","timestamp":1715068020230,"user_tz":-480,"elapsed":13,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-4S8vGCIK8S","executionInfo":{"status":"ok","timestamp":1715068020230,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["import time\n","import numpy as np\n","import pandas as pd\n","import scipy.optimize\n","import warnings\n","\n","import custom_utility as cu\n","from os import listdir\n","from os.path import isfile, join"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oXcq2kWSIXAZ"},"source":["# Code Configurations"]},{"cell_type":"code","metadata":{"id":"J6BeyWQkIbtp","executionInfo":{"status":"ok","timestamp":1715068020230,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["# np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","# using 'raw_real_data.csv' or 'test_case_1a.csv'\n","# RAWDATA_CSV_PATH_FILENAME = 'test_case_1a.csv'\n","# real_world_data\n","RAWDATA_CSV_PATH_FILENAME = 'real_world_data.csv'\n","# REPORT_PATH_FILENAME = \"yield_rate_report_v1.2.csv\"\n","# REPORT_PATH_FILENAME = \"report_test_case_1a.csv\"\n","REPORT_PATH_FILENAME = \"report_real_world_data.csv\"\n","MAX_EMA_ITERATIONS = 25\n","EPSILON = 1.e-99 # a small positive infinitesimal quantity\n","OLD_COLUMNS = {\"lot name\" : 'Lot',\n","               \"process prefix\" : 'Process',\n","               \"process suffix\" : '_MachineNo',\n","               \"lot step\" : 'Final',\n","               \"processed\" : 'CurrentTotalNum',\n","               \"bad pieces\" : 'BadNum',\n","               \"total lot pieces\" : 'TotalNum'\n","              }\n","NEW_COLUMNS = {\"lot name\" : 'lot_name',\n","               \"process prefix\" : 'lot_machine_step',\n","               \"lot step\" : 'lot_step',\n","               \"processed\" : 'processed',\n","               \"bad pieces\" : 'bad_pieces',\n","              }"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jC7HEeNiLbAR"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"lbSVQa3tLiCx"},"source":["## Read CSV file"]},{"cell_type":"code","metadata":{"id":"qFAeNKXaLekZ","executionInfo":{"status":"ok","timestamp":1715068020231,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def read_csv_files(filename):\n","\n","    \"\"\"\n","    read the preprocessed data with given path and filename:\n","\n","    Parameter:\n","    ----------\n","    filename : str\n","        given path and filename such as ``\"folder/yourfilename.csv\"``\n","\n","    Return:\n","    ----------\n","    raw_csv : DataFrame or TextParser (2D array)\n","        full data from your csv.\n","\n","    \"\"\"\n","    #read the chinese character with encoding big5\n","    #raw_csv = pd.read_csv(filename, encoding='big5', low_memory=False)\n","    raw_csv = pd.read_csv(filename, encoding='big5',\n","                          iterator=True, chunksize=10000)\n","    raw_csv = pd.concat(raw_csv, ignore_index=True)\n","\n","    # renaming columns if lot name columns appear as old name\n","    if OLD_COLUMNS[\"lot name\"] in raw_csv.columns:\n","        # make sure the conversion of process column\n","        _col_1 = len(set(raw_csv.CurrentTotalNum))\n","        _col_2 = len(set(raw_csv.TotalNum))\n","        process_col = 'CurrentTotalNum'\n","        if _col_1 < _col_2:\n","            process_col = 'TotalNum'\n","\n","\n","        #rename default name\n","        raw_csv.rename(columns={\n","            OLD_COLUMNS[\"lot name\"]: NEW_COLUMNS[\"lot name\"],\n","            OLD_COLUMNS[\"lot step\"]: NEW_COLUMNS[\"lot step\"],\n","            process_col: NEW_COLUMNS[\"processed\"],\n","            OLD_COLUMNS[\"bad pieces\"]: NEW_COLUMNS[\"bad pieces\"]\n","        }, inplace=True)\n","\n","        # remove old process column suffix\n","        raw_csv.columns = [col.replace(OLD_COLUMNS[\"process suffix\"], '')\n","                           for col in raw_csv.columns]\n","        # rename all prefix of machine process column\n","        raw_csv.columns = [col.replace(OLD_COLUMNS[\"process prefix\"],\n","                                       NEW_COLUMNS[\"process prefix\"])\n","                           for col in raw_csv.columns]\n","\n","    # fix unconsistent bad pieces:\n","    # when processed pieces is reduced in next row [shift(-1)],\n","    # then re-calculate all bad pieces in current row\n","    # except for the last step (-1)\n","    raw_csv['all_bad_pieces'] = raw_csv.bad_pieces\n","    raw_csv.loc[raw_csv['lot_step'] != -1, 'all_bad_pieces'] \\\n","        =  raw_csv.processed - raw_csv.processed.shift(-1)\n","    return raw_csv"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"leH_1LjyLpnJ"},"source":["## One Hot Encoding"]},{"cell_type":"code","metadata":{"id":"DCWKYTg4LwLJ","executionInfo":{"status":"ok","timestamp":1715068020231,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def get_onehot_machine(source_data):\n","    \"\"\"\n","    preprocess the machine name in each step with one hot encoding, then return\n","    hotencoding including machine name and updated source data.\n","\n","    Parameter:\n","    ----------\n","    source_data : DataFrame (2D array)\n","        insert full source data from your csv.\n","\n","    Return:\n","    ----------\n","    onehot_last_step : DataFrame (2D array)\n","        an each machine step feature in one hot encoding format, with\n","        machine name as its columns name\n","    machine_name : DataFrame (2D array)\n","        a machine information dataframe which only consist of machine name.\n","    source_data : DataFrame (2D array)\n","        full data source from your csv, but added a new column called\n","        ``lot_step_machines`` which consist of machines name that used in\n","        each LOT's step\n","\n","    \"\"\"\n","    #select the machine step columns (backslash to break, avoid long lines)\n","    #select column \"ProcessXXX_MachineNo\"\n","    machine_step_data = source_data.loc[:, source_data.columns.str.                 \\\n","                                        startswith(\"lot_machine_step\")]\n","\n","    # one hot encoding with pandas \"get_dummies\" and\n","    # different column and same values is seen as one values\n","    onehot_machine_step = pd.get_dummies(machine_step_data,\n","                                         prefix='',\n","                                         prefix_sep=''\n","                                        ).astype(np.int8).max(level=0 ,axis=1)\n","\n","    # get last step index of each LOT (from raw data)\n","    last_step_index = source_data.lot_step[source_data.lot_step == -1]  \\\n","                                 .index                                 \\\n","                                 .tolist()\n","\n","    # filter the index based on last step raw data for one hot encoding\n","    onehot_last_step = onehot_machine_step.iloc[last_step_index]\n","    # machine name as dataframe\n","    machine_name = pd.DataFrame({'machine_name':list(onehot_last_step)})\n","    #machine_name['index'] = machine_name.index\n","\n","    #get the machine used for every row, based on machine config\n","    lot_step_machines = machine_step_data.copy()\n","\n","    # change dataframe to tuple in 4 steps\n","    # Step 1: get non NaN/Null value each row using \"stack\" data structure\n","    lot_step_machines = lot_step_machines.stack()\n","    # Step 2: group by dataframe row / index value (level=0)\n","    lot_step_machines = lot_step_machines.groupby(level=0)\n","    # Step 3: change to list for each row using apply depends on group by\n","    lot_step_machines = lot_step_machines.apply(list)\n","    # Step 4: change to tuple of list\n","    lot_step_machines = tuple(lot_step_machines) # change to tuple of list\n","\n","    # modify the raw data to add new column\n","    source_data['lot_step_machines'] = lot_step_machines\n","\n","    return onehot_last_step, machine_name, source_data"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6kD6BplLx3h"},"source":["## Analyzing Lot/Batch Statistics"]},{"cell_type":"code","metadata":{"id":"bCpE_iywL7jJ","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def get_lot_information(source_data):\n","    \"\"\"\n","    read the statistic of each lot in given source dataframe.\n","\n","    Parameter:\n","    ----------\n","    source_data : DataFrame (2D array)\n","        insert full data from your csv.\n","\n","    Return:\n","    ----------\n","    lot_info : DataFrame or TextParser (2D array)\n","        A statistical dataframe consist of 'lot_name', 'machine_used',\n","        'lot_total_pieces', 'lot_good_pieces', 'lot_yield_rate',\n","        and 'ln_lot_yield_rate' for each LOT.\n","\n","    \"\"\"\n","    # function to avoid ZeroDivisionError, and replace result to near zero\n","    def safe_division(x, y):\n","        if x == 0 or y == 0:\n","            return EPSILON\n","        return x/y\n","\n","    # initializing dataframe\n","    _columns = ['lot_name', 'machine_used', 'lot_total_pieces',\n","                'lot_good_pieces', 'lot_bad_pieces', 'lot_yield_rate',\n","                'ln_lot_yield_rate']\n","    lot_info = pd.DataFrame(data=None, columns=_columns)\n","\n","    # groping the raw data based on LOT Name\n","    lot_group = source_data.groupby('lot_name')\n","\n","    # calculating all columns value in lot_info for each row / each LOT\n","    for _lot_name, _lot_data in lot_group:\n","        # get row where lot_step = -1\n","        last_step = _lot_data.loc[_lot_data.lot_step == -1]\n","\n","        # fix unconsistent bad pieces:\n","        # find delta between all bad pieces and micro crack bad pieces\n","        lot_all_defect = _lot_data.all_bad_pieces.sum()\n","        lot_all_microcrack = _lot_data.bad_pieces.sum()\n","        lot_badpieces_delta = lot_all_defect - lot_all_microcrack\n","\n","        # get data for lot_info\n","        # use .item() to get the value of groupby cells -- deprecated, use iat[0]\n","        machine_used = last_step.lot_step_machines.iat[0] #.item()\n","        # syncronized with only micro crack defect\n","        lot_total_pieces = _lot_data.processed.max() - lot_badpieces_delta\n","        lot_good_pieces = last_step.processed.iat[0] - last_step.bad_pieces.iat[0]\n","        lot_bad_pieces = lot_total_pieces - lot_good_pieces\n","\n","        # use function to safely process the division\n","        lot_yield_rate = safe_division(lot_good_pieces, lot_total_pieces)\n","        ln_lot_yield_rate = np.log(lot_yield_rate)\n","\n","        #append to the list based on _columns name\n","        current_lot_info = [_lot_name, machine_used, lot_total_pieces,\n","                            lot_good_pieces, lot_bad_pieces,  lot_yield_rate,\n","                            ln_lot_yield_rate]\n","\n","        #append to statistic dataframe\n","        lot_info.loc[len(lot_info)] = current_lot_info\n","\n","    return lot_info"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EtWU9ImMAXZ"},"source":["## Analyzing Machines Statistics"]},{"cell_type":"code","metadata":{"id":"MhxqPQnJMEWZ","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def get_machine_information(onehot_lot_data, machine_info, lot_info):\n","    \"\"\"\n","    calculate the statistic of each machine from several related sources.\n","\n","    Parameter:\n","    ----------\n","    onehot_lot_data : DataFrame (2D array)\n","        Dataframe consist of each machine step feature in one hot encoding\n","        format, with machine name as its columns name\n","    machine_info : DataFrame (2D array)\n","        A machine information dataframe which only consist of machine name.\n","    lot_info : DataFrame (2D array)\n","        An information dataframe for each LOT.\n","\n","    Return:\n","    ----------\n","    machine_info : DataFrame or TextParser (2D array)\n","        A machine information dataframe consist of 'machine_name',\n","        'good_produced', 'init_yieldrate', and 'em_yieldrate' for each machine.\n","\n","    \"\"\"\n","    # Step 1: Calculating Good Pieces Produced for each machine\n","    # initializing dataframe\n","    machine_info['good_produced'] = 0\n","\n","    # for faster indexing, first, change dataframe to dictionary\n","    # dict(zip(keys, values)) --> to change 2 lists to single dictionary\n","    machine_info = dict(zip(machine_info.machine_name,\n","                            machine_info.good_produced))\n","\n","    # calculate good produced for each machine based on LOT's machine usage\n","    for _, lot_step in lot_info.iterrows():\n","\n","        # Optimizing: caching variable for faster get value\n","        machine_used = lot_step.machine_used\n","        good_pieces = lot_step.lot_good_pieces\n","\n","        for machine in machine_used:\n","            # add or sum good pieces to previous value\n","            machine_info[machine] += good_pieces\n","\n","    #change back to dataframe\n","    machine_info = pd.DataFrame(list(machine_info.items()),\n","                                columns=['machine_name', 'good_produced'])\n","\n","    # Step 2: Calculating initial yield rate for each machine\n","    machine_info['init_yieldrate'] = init_yieldrate_est(onehot_lot_data, lot_info)\n","\n","    return machine_info"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0GLAcmCFMIU5"},"source":["## Calculating Initial Yield Rate"]},{"cell_type":"code","metadata":{"id":"uL_yCuvvMNoJ","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def init_yieldrate_est(onehot_data, lot_info):\n","    \"\"\"\n","    calculating each machine's initial yieldrate using Least Square and\n","    L-BFGS-B (Limited-memory BFGS).\n","    see: `scipy.optimize.fmin_l_bfgs_b <https://docs.scipy.org/doc/scipy/\n","    reference/generated/scipy.optimize.fmin_l_bfgs_b.html>`_\n","\n","    Parameter:\n","    ----------\n","    onehot_lot_data : dataframe (2D array)\n","        insert the onehot encoding data of the LOT's Last Step\n","    lot_info : dataframe (2D array)\n","        insert a dataframe which consist of statistic details of each lot\n","\n","    Return:\n","    ----------\n","    est_yieldrate : list or 1D array\n","        the yield rate probability using least square algorithm, and minimized\n","        by a function of L-BFGS-B algorithm.\n","\n","    \"\"\"\n","\n","    #initializing yield rate estimation with all zeros\n","    max_machine_step = len(onehot_data.columns)\n","    log_est_yieldrate = np.zeros((max_machine_step,))\n","\n","    #lot onehot where step == -1\n","    onehot_data = onehot_data.values #convert to array --> as X on formula\n","\n","    #get initial yield rate as array\n","    lot_info = lot_info[\"ln_lot_yield_rate\"].values\n","    #reshape array with any rows but with 1 column\n","    lot_yieldrate = lot_info.reshape(-1, 1)  #--> as Y on formula\n","\n","    #calculate dot product for config and yield rate\n","    config_dot_config = onehot_data.T.dot(onehot_data)  #--> X^2\n","    config_dot_yield = onehot_data.T.dot(lot_yieldrate) #--> X.Y\n","\n","    # least Square\n","    def perform_least_square(params, cfg, i_yr, c_dot_c, c_dot_y):\n","        \"\"\"\n","        using Limited-memory BFGS\n","        see: `scipy.optimize.fmin_l_bfgs_b <https://docs.scipy.org/doc/scipy/\n","        reference/generated/scipy.optimize.fmin_l_bfgs_b.html>`_\n","        \"\"\"\n","        yieldrate = (c_dot_c.dot(params.reshape(-1, 1)) - c_dot_y) / 2\n","        val = cfg.dot(params.reshape(-1, 1)) - i_yr\n","        val *= val\n","        return val.sum()/2, yieldrate\n","\n","    #Minimize a function using the L-BFGS-B algorithm.\n","    log_est_yieldrate = scipy.optimize.fmin_l_bfgs_b        \\\n","                        (perform_least_square,\n","                         log_est_yieldrate,\n","                         None, (onehot_data,\n","                                lot_yieldrate,\n","                                config_dot_config,\n","                                config_dot_yield\n","                               ),\n","                         False,\n","                         [(None, 0) for _ in range(max_machine_step)])\n","\n","    #restore from np.log in initial yield rate (remove min and info)\n","    est_yieldrate = np.exp(log_est_yieldrate[0])\n","\n","    return est_yieldrate"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70o9Auf6MP4i"},"source":["# EM Algorithm"]},{"cell_type":"markdown","metadata":{"id":"BvL7-CafMWvZ"},"source":["## E-Step"]},{"cell_type":"code","metadata":{"id":"Fx7BwcnZMUEh","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":11,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def e_step(source_data, machine_info):\n","    \"\"\"\n","    The E-STEP of Expectation–Maximization (EM) algorithm.\n","    This step is used to calculate the hidden variable or Expectation of\n","    bad pieces in each machine, hence can provide the estimation of the number\n","    of bad pieces and the number of good pieces produced by each machine.\n","\n","    Parameter:\n","    ----------\n","    source_data : dataframe (2D array)\n","        full data from your csv, including the 'lot_step_machines' column.\n","    machine_info : dataframe (2D array)\n","        A machine information dataframe for each machine.\n","\n","    Return:\n","    ----------\n","    machine_info : dataframe (2D array)\n","        A machine information dataframe for each machine that already updated\n","        with adding some columns including 'exp_num_bad_pieces',\n","        'exp_pieces_going_bad', and 'exp_num_good_pieces'.\n","\n","    \"\"\"\n","\n","    #initializing or reset the curent value to recalculate later\n","    machine_info['exp_num_bad_pieces'] = 0      # reset\n","    machine_info['exp_pieces_going_bad'] = 0    # reset\n","    dict_exp_bad = dict(zip(machine_info.machine_name,\n","                            machine_info.exp_num_bad_pieces))\n","    dict_going_bad = dict(zip(machine_info.machine_name,\n","                              machine_info.exp_pieces_going_bad))\n","\n","    # creating dictionary for faster lookup in dataframe\n","    # dict(zip(keys, values)) --> to change 2 lists to single dictionary\n","    cur_yieldrate = dict(zip(machine_info.machine_name,\n","                             machine_info.em_yieldrate))\n","\n","    cur_log_yieldrate = dict(zip(machine_info.machine_name,\n","                                 machine_info.ln_yieldrate))\n","\n","    # Calculation is going through all LOT's steps\n","    for _, lot_step in source_data.iterrows():\n","\n","        # Optimizing: caching bad_pieces (for faster get value)\n","        obs_bad_pieces = lot_step.bad_pieces\n","\n","        # E-Step: Ignore Zero bad Pieces\n","        if obs_bad_pieces > 0:\n","            # Optimizing: caching lot_step_machines (for faster get value)\n","            lot_step_machines = lot_step.lot_step_machines\n","\n","            ### BEGIN Calculate Number of Expected Bad Pieces ###\n","            exp_bad_pieces = []\n","\n","            for step_number, machine in enumerate(lot_step_machines):\n","\n","                # Calculating E-Step point B1 (see design layout slide 42)\n","                bad_estimation_b1 = 1 - cur_yieldrate[machine]\n","\n","                # Calculating E-Step point B2 (see design layout slide 42)\n","                # callculating in Log version\n","                bad_estimation_b2 = 0\n","                previous_machines = lot_step_machines[0:step_number]\n","                for _machine in previous_machines:\n","                    bad_estimation_b2 += cur_log_yieldrate[_machine]\n","\n","                # leaving log version\n","                bad_estimation_b2 = np.exp(bad_estimation_b2)\n","\n","                # E-Step: B1 * B2\n","                # + EPSILON is to avoid true_divide (sum value is zero)\n","                bad_estimation = bad_estimation_b1 * bad_estimation_b2 + EPSILON\n","                exp_bad_pieces.append(bad_estimation)\n","\n","\n","            #calculating % bad pieces for each machine in each LOT row\n","            exp_percent_bad_pieces = (exp_bad_pieces / sum(exp_bad_pieces))\n","\n","            #calculating number of bad pieces for each machine in each LOT row\n","            exp_num_bad_pieces = (obs_bad_pieces * exp_percent_bad_pieces)\n","\n","            ### END OF Calculate Percentage of Number Bad Pieces ###\n","\n","            ### BEGIN Calculate Expected Pieces Going Bad ###\n","            # start with all zero\n","            exp_pieces_going_bad = np.zeros((len(exp_num_bad_pieces),))\n","\n","            # reversed loop, calculate from the last index\n","            # https://stackoverflow.com/questions/529424/\n","            # traverse-a-list-in-reverse-order-in-python\n","            for step_number, exp_bad_pieces         \\\n","                        in reversed(list(enumerate(exp_num_bad_pieces))):\n","\n","                #stop before index = 0\n","                if step_number > 0:\n","                    exp_pieces_going_bad[step_number-1]         \\\n","                            = exp_bad_pieces                    \\\n","                              + exp_pieces_going_bad[step_number]\n","\n","            ### END OF Calculate Expected Pieces Going Bad ###\n","\n","            # merged bad and going_bad pieces to the appropriate machine\n","            for step_number, machine in enumerate(lot_step_machines):\n","                dict_exp_bad[machine] += exp_num_bad_pieces[step_number]\n","                dict_going_bad[machine] += exp_pieces_going_bad[step_number]\n","\n","    # after LOT's steps iteration\n","    # maerge dictionaries to main machine information dataframe\n","    machine_info['exp_num_bad_pieces'] = machine_info['machine_name'].map(dict_exp_bad)\n","    machine_info['exp_pieces_going_bad'] = machine_info['machine_name'].map(dict_going_bad)\n","\n","    # calculating Number of Expected Good Pieces for each machine\n","    machine_info['exp_num_good_pieces'] = machine_info['exp_pieces_going_bad'] \\\n","                                          + machine_info['good_produced']\n","\n","    return machine_info"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMamBYxYMamx"},"source":["## M-Step"]},{"cell_type":"code","metadata":{"id":"4EtFSxHkMcSR","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":11,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def m_step(machine_info):\n","    \"\"\"\n","    The M-STEP of Expectation–Maximization (EM) algorithm.\n","    This step is used to RE-calculate the yield rate (parameter) of each machine\n","    based on the estimated number of bad pieces and the estimated number of\n","    good pieces calculated in E-STEP of EM Algorithm.\n","\n","    Parameter:\n","    ----------\n","    machine_info : dataframe (2D array)\n","        A machine information dataframe for each machine that already updated\n","        with adding some columns including 'exp_num_bad_pieces' and\n","        'exp_num_good_pieces'.\n","\n","    Return:\n","    ----------\n","    machine_info : dataframe (2D array)\n","        An updated machine information dataframe for each machine which the\n","        'em_yieldrate' column is already recalculate based on the E-STEP\n","        estimation.\n","\n","    \"\"\"\n","    machine_info['sum_exp'] = machine_info['exp_num_bad_pieces']            \\\n","                              + machine_info['exp_num_good_pieces']\n","\n","    # RE-calculate the yield rate of each machine,\n","    # change NaN value with zeros\n","    machine_info['em_yieldrate'] = (machine_info['exp_num_good_pieces']     \\\n","                                    / machine_info['sum_exp']               \\\n","                                   ).replace(np.nan, 0)\n","\n","    return machine_info"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2qLhVViRMfN6"},"source":["## Run EM Iterations"]},{"cell_type":"code","metadata":{"id":"jFSeoUqnMol5","executionInfo":{"status":"ok","timestamp":1715068020232,"user_tz":-480,"elapsed":10,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def em_algorithm(source_data, mach_info, lot_info):\n","    \"\"\"\n","    Expectation–Maximization (EM) algorithm. Return most optimal or converged\n","    yieldrate.\n","\n","    Parameter:\n","    ----------\n","    source_data : dataframe (2D array)\n","        full data from your csv, including the 'lot_step_machines' column.\n","    mach_info : dataframe (2D array)\n","        A machine information dataframe for each machine.\n","\n","    Return:\n","    ----------\n","    machine_info : dataframe (2D array)\n","        An updated machine information dataframe for each machine. The column of\n","        'em_yieldrate' is already calculated by EM algorithm, and can be a\n","        benchmark for each machine's yield rate.\n","\n","    \"\"\"\n","    # initializing variables\n","    mach_info['em_yieldrate'] = mach_info['init_yieldrate']\n","\n","    # record for EM iterations\n","    em_update = pd.DataFrame(data=None, columns=['last', 'current', 'diff'])\n","\n","    #Start EM Iteration until Max Iteration\n","    for iters in range(MAX_EMA_ITERATIONS):\n","        # initializing\n","        # If some element of yieldrate <= 0 then replaces with a very small number\n","        mach_info['em_yieldrate'] = np.where(mach_info['em_yieldrate'] <= 0,\n","                                             EPSILON,\n","                                             mach_info['em_yieldrate'])\n","        mach_info['ln_yieldrate'] = np.log(mach_info['em_yieldrate'])\n","        mach_info['prev_yieldrate'] = mach_info['em_yieldrate']\n","\n","        # E-STEP ###\n","        mach_info = e_step(source_data, mach_info)\n","\n","        # M-STEP ###\n","        mach_info = m_step(mach_info)\n","\n","        #show accuracy each iteration\n","        #_, accuracy, lot_bp_acc = em_accuracy(mach_info, lot_info)\n","\n","        # Calculating Stop Condition\n","        tolerance = 1.e-3\n","        #it could save the update history for each iteration\n","        prev_yr = mach_info['prev_yieldrate'].values.copy()\n","        cur_yr = mach_info['em_yieldrate'].values.copy()\n","        diff = np.linalg.norm(prev_yr - cur_yr)\n","\n","        #save to update record\n","        em_update.loc[len(em_update)] = [prev_yr, cur_yr, diff]\n","\n","        \"\"\"\n","        #show current progress / iteration\n","        cu.show_progress(iters+1, MAX_EMA_ITERATIONS,\n","                         messages=\"iteration: %d/%d;\"\n","                         %(iters+1, MAX_EMA_ITERATIONS),\n","                         force_show=True)\n","        \"\"\"\n","        #stop condition\n","        if diff <= tolerance:\n","            break\n","\n","    #print()\n","\n","    return mach_info, em_update, iters+1"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RXdqoJdxMuOC"},"source":["# Report"]},{"cell_type":"code","metadata":{"id":"LYEVUAk4Mx6q","executionInfo":{"status":"ok","timestamp":1715068020233,"user_tz":-480,"elapsed":11,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}}},"source":["def create_report(machine_info, target_filename):\n","    \"\"\"\n","    Saving report to csv file. this will save only the yield rate and bad pieces\n","    per machine step.\n","\n","    Parameter:\n","    ----------\n","    machine_statistic : DataFrame (2D array)\n","        a machine statistic dataframe which already processed by EM algorithm\n","        and have bad pieces information\n","    target_filename : str\n","        given path and filename such as ``\"folder/yourfilename.csv\"``\n","\n","    \"\"\"\n","    #sort by yieldrate from the smallest and get some report summary\n","    machine_info = machine_info.sort_values('em_yieldrate')\n","    report = machine_info[['em_yieldrate', 'exp_num_bad_pieces', 'machine_name']]\n","\n","    #renaming columns to match to the dictionary documents\n","    report.columns = ['YieldRate', 'BadPiece', 'Machine']\n","    report = report.reset_index(drop=True)\n","\n","    #changing display options to set print all column\n","    pd.set_option('display.max_columns', None)\n","    report = report.round(5) #cleaning some decimal\n","    #print(report)\n","\n","    #saving report summaries\n","    report.to_csv(target_filename, sep=',', index=False)\n","\n","    #check file\n","    check = pd.read_csv(target_filename, index_col=0)\n","    print(\"Saving %s Success\" %(target_filename)\n","            if check.size == check.size \\\n","            else \"Saving Report %s failed\" %(target_filename))\n","\n","    #reset display options\n","    pd.reset_option('^display.', silent=True)\n","\n","    return report"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zen7Z4giM5vJ"},"source":["# Run EM Algorithm v1.2"]},{"cell_type":"code","metadata":{"id":"FWqzU07xNDCq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715068085771,"user_tz":-480,"elapsed":65549,"user":{"displayName":"Judy Su","userId":"07681016814736646807"}},"outputId":"ac4835de-a8e9-4b9c-aec7-21a3d190df37"},"source":["def main(source_filename, report_filename):\n","    \"\"\"\n","    Main procedure for running the EM Algorithm\n","\n","    Parameter:\n","    ----------\n","    source_filename, report_filename : str\n","        given path and filename such as ``\"folder/yourfilename.csv\"``\n","\n","    \"\"\"\n","    start = time.time()\n","    print('Process Start: ', source_filename)\n","\n","    # STEP 1: get raw data\n","    #print('Step 1: Reading CSV')\n","    raw_data = read_csv_files(source_filename)\n","    print(raw_data.head())\n","\n","\n","    #start_split = time.time()\n","    #print('Step 2: One Hot Encoding of Machine Steps')\n","    # STEP 2: create one hot encoding for each machine step\n","    # and add lot machine usage to raw_data\n","    onehot_lot_last_step, machine_information, raw_data = get_onehot_machine(raw_data)\n","\n","\n","    #start_split = time.time()\n","    #print('Step 3: Preprocesing: Lot Information')\n","    # STEP 3: calculate each LOT's statistics\n","    lot_information = get_lot_information(raw_data)\n","\n","\n","    #start_split = time.time()\n","    #print('Step 4: Preprocesing: Machine Information')\n","    # STEP 4: calculate each machine's statistics\n","    machine_information = get_machine_information(onehot_lot_last_step, machine_information, lot_information)\n","\n","\n","    #start_split = time.time()\n","    #print('Step 5: Running EM Algorithm')\n","    # STEP 5: calculate machine's yield rate using EM Algorithm\n","    machine_information, em_iter_res, iters = em_algorithm(raw_data, machine_information, lot_information)\n","\n","    # STEP 6: creating reports\n","    #print('Step 6: Saving Report')\n","    report = create_report(machine_information, report_filename)\n","\n","    #print the processing time\n","    #print('Process End')\n","    print('Process End: ', source_filename)\n","    cu.check_time(start, time.time())\n","    #print()\n","\n","    return raw_data, onehot_lot_last_step, machine_information, lot_information, \\\n","           machine_information, em_iter_res, iters, report\n","\n","if __name__ == \"__main__\":\n","    raw_data, onehot_lot_last_step, machine_information, lot_information, \\\n","    machine_information, em_iter_res, last_iters, report = main(RAWDATA_CSV_PATH_FILENAME, REPORT_PATH_FILENAME)\n","\n","    print(report)"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Process Start:  real_world_data.csv\n","              lot_name lot_machine_step001 lot_machine_step002  \\\n","0  WB2018400438-C00001              FN-004                 NaN   \n","1  WB2018400438-C00001              FN-004              PT-106   \n","2  WB2018400438-C00001              FN-004              PT-106   \n","3  WB2018400438-C00001              FN-004              PT-106   \n","4  WB2018400438-C00001              FN-004              PT-106   \n","\n","  lot_machine_step003 lot_machine_step004 lot_machine_step005  \\\n","0                 NaN                 NaN                 NaN   \n","1                 NaN                 NaN                 NaN   \n","2              FN-007                 NaN                 NaN   \n","3              FN-007              PT-106                 NaN   \n","4              FN-007              PT-106              FN-010   \n","\n","  lot_machine_step006 lot_machine_step007 lot_machine_step008  \\\n","0                 NaN                 NaN                 NaN   \n","1                 NaN                 NaN                 NaN   \n","2                 NaN                 NaN                 NaN   \n","3                 NaN                 NaN                 NaN   \n","4                 NaN                 NaN                 NaN   \n","\n","  lot_machine_step009  ... lot_machine_step031 lot_machine_step032  \\\n","0                 NaN  ...                 NaN                 NaN   \n","1                 NaN  ...                 NaN                 NaN   \n","2                 NaN  ...                 NaN                 NaN   \n","3                 NaN  ...                 NaN                 NaN   \n","4                 NaN  ...                 NaN                 NaN   \n","\n","  lot_machine_step033 lot_machine_step034 lot_machine_step035 lot_step  \\\n","0                 NaN                 NaN                 NaN        1   \n","1                 NaN                 NaN                 NaN        2   \n","2                 NaN                 NaN                 NaN        3   \n","3                 NaN                 NaN                 NaN        4   \n","4                 NaN                 NaN                 NaN        5   \n","\n","  processed bad_pieces TotalNum all_bad_pieces  \n","0        25          0       25              0  \n","1        25          0       25              0  \n","2        25          0       25              0  \n","3        25          0       25              0  \n","4        25          0       25              0  \n","\n","[5 rows x 41 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-46-984773928a32>:31: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n","  onehot_machine_step = pd.get_dummies(machine_step_data,\n"]},{"output_type":"stream","name":"stdout","text":["Saving report_real_world_data.csv Success\n","Process End:  real_world_data.csv\n","Time elapsed: 0 H : 1 M : 5.463 Sec\n","     YieldRate     BadPiece Machine\n","0      0.04802     80.30365  LS-061\n","1      0.78655  21668.87927  PL-021\n","2      0.88132   6508.92055  SW-026\n","3      0.88493  13922.59752  LS-070\n","4      0.89059   2286.76895  GA-549\n","..         ...          ...     ...\n","211    1.00000      0.00000  FT-044\n","212    1.00000      0.00000  LS-068\n","213    1.00000      0.00000  AL-003\n","214    1.00000      0.00000  LS-064\n","215    1.00000      0.00000  CR-025\n","\n","[216 rows x 3 columns]\n"]}]}]}